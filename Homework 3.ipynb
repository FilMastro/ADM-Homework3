{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a467159-5ea8-4866-af78-a8195b9b4839",
   "metadata": {},
   "source": [
    "# Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21b36632-1431-4cd7-861b-9409d775fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "import collections\n",
    "import heapq as hq\n",
    "from scipy.sparse import dia_matrix\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e86cc8-27ea-4e30-8aa2-34872b1f9217",
   "metadata": {},
   "source": [
    "# Loading assets from the folder\n",
    "These assets will be created down in the depths of the notebook and since it is a long procedure we decided to store and load them afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ef755b7-dfe8-438b-9bec-4aa676c5f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframe\n",
    "df = pd.read_csv('Animeds.csv')\n",
    "word_index = pd.read_pickle('word_index.pkl')\n",
    "vocab_2 = pd.read_pickle('vocabulary.pkl')\n",
    "inverted_index_2 = pd.read_pickle('inverted index 2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6bbf5-b3a4-46a7-903f-fe3cfb1c51fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67cf9c-4fd6-460c-8c83-50aabbeb190e",
   "metadata": {},
   "source": [
    "## 1.1 Get the list of animes\n",
    "\n",
    "With the for loop I get the url of all the pages (50 per page except the last one which has less,383 pag). We 'send' a request to the page, to collect the ursl. We read the html and take the href attributes of the tag. The command tqdm is useful because it shows the progress status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f4c6c-90d8-49b1-8309-cdfa7381cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in tqdm(range(0,20000,50)):\n",
    "  url='https://myanimelist.net/topanime.php?limit='+str(i)\n",
    "  \n",
    "  soup= BeautifulSoup(requests.get(url).text,'html.parser')\n",
    "\n",
    "  for tag in soup.find_all('tr'):\n",
    "    links=tag.find_all('a')\n",
    "    for l in links:\n",
    "      if type(l.get('id'))== str and len(l.contents[0]) >1:\n",
    "        urls.append(l.get('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef0745-0bbd-4145-920b-d7e80a765781",
   "metadata": {},
   "source": [
    "We need to save it as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be32e20-7d43-4711-8af8-340494cd4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('urls.txt', 'w', encoding='utf-8') as f: \n",
    "    for line in urls:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7d228-9851-4a18-872b-c2851605bced",
   "metadata": {},
   "source": [
    "## 1.2 Crawl animes\n",
    "\n",
    "Create the folders. Put all of them under \"pages\". Each folder has a name that refers to the number of the page from which the links it contains come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927b2df-a647-425e-945d-b36da8a93a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in tqdm(range(1, 384)):\n",
    "    folder = \"page\"+str(page)\n",
    "    path = \"/content/drive/MyDrive/Anime_folder\"+folder\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f929372-d3ab-4865-9403-7e3272c2eed1",
   "metadata": {},
   "source": [
    "Try for the first 150:ok. Try to collect them in group of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc40289-b697-4843-8f0e-c7652ada0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in tqdm(range(4, 5)): \n",
    "   \n",
    "  folder = \"/content/drive/MyDrive/Anime_folderpage\"+str(page+1)\n",
    "  update_page = 50*page\n",
    "  for i in range(0,50): \n",
    "    time.sleep(3) \n",
    "    url = f'{urls[update_page+i]}'\n",
    "    response = requests.get(url)   \n",
    "    filename = r\"\"+folder+\"/anime_\"+str(update_page+i+1)+\".html\"\n",
    "    with open(filename,'w', encoding='utf-8') as f:\n",
    "      f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a86cf7-47e6-4fa0-b012-90396793a012",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3 Parsing downloaded pages.\n",
    "Here I created a function to extract each of the features that we need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec4fec-2ab8-4a6b-8446-e9fd8993e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeTitle(html):\n",
    "  with open(html,'r') as f:\n",
    "    soup= BeautifulSoup(f, 'html.parser')\n",
    "    animeTitle=soup.find(\"h1\", attrs = {\"class\": \"title-name h1_bold_none\"}).string\n",
    "    return(animeTitle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e526f-4813-4918-b1b8-14a597d9aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeTitle('/content/to8760/article_4016.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873ae46-f5ea-4086-b3ee-9f258bc0af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeScore(html):\n",
    "  with open(html,'r') as f:\n",
    "    soup= BeautifulSoup(f)\n",
    "    for i in range(10):\n",
    "      score=soup.find_all('div' ,attrs = {\"class\": \"score-label score-\"+str(i)})\n",
    "      for j in score:\n",
    "        return float(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50eaba-63d1-423e-8bb5-938efd0e8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeScore('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bc8be-0fff-4069-8528-cb9daca22682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeRank(html):\n",
    "  with open(html,'r') as f:\n",
    "    soup= BeautifulSoup(f,'html.parser')\n",
    "    b= soup.find('span',{'class':'numbers ranked'})\n",
    "    rank=int(b.find('strong').contents[0].strip()[1:])  \n",
    "    return(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5898f0-fdf5-4c6b-85cc-fd059d205b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeRank('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983e248-396c-45ba-88ef-99caab31c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeNumberofepisode(html_string):\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A=soup.find(text=re.compile('Episodes:')).parent.parent.text.split()[-1]      \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d6a4d-d68f-44df-bbb7-e02ec89020fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeNumberofepisode('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598d30a-d563-4b96-914e-f41215ec2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animePopularity(html):\n",
    "  with open(html,'r') as f:\n",
    "    soup= BeautifulSoup(f,'html.parser')\n",
    "    rank=int(str(soup.find(class_=\"numbers popularity\").text).split('#')[-1])  \n",
    "    return(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae17752-1e06-43ed-842e-4c18fdf05674",
   "metadata": {},
   "outputs": [],
   "source": [
    "animePopularity('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea4e47-c123-46fc-ab2f-c75f910524e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeDescription(html_string): #I think that this function works well.\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    A=soup.find(itemprop=\"description\")\n",
    "    return A.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0fe63-a1c1-47cc-8e91-46396da1e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeDescription('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c9339-cf49-4493-9aaf-22a64316f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeUsers(html_string): \n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    A=soup.find(itemprop=\"ratingCount\")\n",
    "    return int(A.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7396ddf-09ed-4d4e-9245-6987f62364a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeUsers('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f283f-b296-494d-b9b3-7da2aaf4d0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def animeType(html_string):\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A=soup.find(text=re.compile('Type:')).parent.parent.text.split()[-1]      \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746d2d7-ce6d-45f8-b8d0-5504207a8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeType('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bd012-41ca-44bf-b6a5-5f2c000db213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fai_date(a: list):\n",
    "    \n",
    "    string = ''\n",
    "    for i in a:\n",
    "        string += i\n",
    "        if i != a[-1]:\n",
    "            string += ' '\n",
    "    string = string.replace(',', '')\n",
    "    date = datetime.strptime(string, '%b %d %Y')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfad7f-f538-4dff-ac4f-f9c5749a1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeRelDate(html_string):\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A= fai_date(soup.find(text=re.compile('Aired:'), class_=\"dark_text\").parent.text.split()[1:4]  ).date()   \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac0c51-b100-41a7-bcde-3b98999c1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeRelDate('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d72962-6906-4a0a-bd57-fe4154d21ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeEndDate(html_string):\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A= fai_date(soup.find(text=re.compile('Aired:'), class_=\"dark_text\").parent.text.split()[5:8]   ).date() \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3c784-a9b7-4fa9-8bbb-1a9fcf6fd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animeEndDate('/content/drive/MyDrive/Anime_folderpage1/anime_1.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fb919-f6b9-4e6d-b5e1-27dc2651f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeRelated(html_string):  \n",
    "  animeRelated = []\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    related = soup.find_all(\"table\", {\"class\":\"anime_detail_related_anime\"})\n",
    "    for i in related:\n",
    "      links = i.find_all('a')\n",
    "      for link in links:        \n",
    "          animeRelated.append(f'{link.contents[0]}')\n",
    "\n",
    "  return (animeRelated)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbad65-f991-4c9d-97e7-ac1d1ed41136",
   "metadata": {},
   "outputs": [],
   "source": [
    " animeRelated('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a03da-c36f-4847-b6e1-9c5ebf3b5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeCharacter(html_string):\n",
    "  personaggi=[]\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A= soup.find_all(class_=\"h3_characters_voice_actors\")    \n",
    "    for a in A:\n",
    "      personaggi.append(a.text)\n",
    "    return(personaggi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf26f0f-3207-429c-88bb-1cf7cbc54145",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeCharacter('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ca3dc-3634-4284-a649-320b5dfa05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeVoices(html_string):\n",
    "  personaggi=[]\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    A= soup.find_all(class_=\"va-t ar pl4 pr4\")   \n",
    "    for a in A:\n",
    "      personaggi.append(a.text)\n",
    "\n",
    "      \n",
    "    return(personaggi) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e0b51-dc2f-4a2f-b542-1d72fb0f72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeVoices('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614aaa72-61e8-45bd-a636-94a9ccad4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animeStaff(html_string):\n",
    "  with open(html_string, 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    divs= soup.find_all('div',{'class':\"detail-characters-list clearfix\"})\n",
    "    i=1\n",
    "    staff=[]\n",
    "    for td in divs[-1].find_all('td',{'class':'borderClass'}):\n",
    "      if (i)==0:\n",
    "        a,small= td.find_all(['small','a'])\n",
    "        staff.append((a.contents[0],small.contents[0].split(',')))\n",
    "      i= (i+1)%2\n",
    "  return(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48470a8d-95a4-48be-b440-ed41d00ce365",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeStaff('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf2770-fa66-4478-817d-5240c1872709",
   "metadata": {},
   "outputs": [],
   "source": [
    " def animeNumMembers(html):\n",
    "  with open(html,'r') as f:\n",
    "    soup= BeautifulSoup(f,'html.parser')\n",
    "    rank=  int(str(soup.find(class_=\"numbers members\").text).split()[1].replace(',', ''))      \n",
    "    return(rank)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6e838-279b-4139-b1b8-afbe44b16c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "animeNumMembers('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8daae-21ea-4912-9213-c4e265690109",
   "metadata": {},
   "source": [
    "### I need to crete a tsv.file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf074d-471b-4665-aa6f-3586f6e8c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "col = ['animeTitle', 'animeType', 'animeNumEpisode', 'releaseDate', 'endDate', 'animeNumMembers', 'animeScore', \\\n",
    "           'animeUsers', 'animeRank', 'animePopularity', 'animeDescription', 'animeRelated', 'animeCharacters', \\\n",
    "           'animeVoices', 'animeStaff']\n",
    "while i < 2600:\n",
    "    \n",
    "    path = '/content/drive/MyDrive/Anime_folderpage'+str(((i-1)//50)+1)+'/anime_'+str(i)+'.html'\n",
    "    dic = {}\n",
    "    \n",
    "    \n",
    "    dic[col[0]] = animeTitle(path)\n",
    "    dic[col[1]] = animeType(path)\n",
    "    dic[col[2]] = animeNumberofepisode(path)\n",
    "    try:\n",
    "      dic[col[3]] = animeRelDate(path)\n",
    "    except Exception:\n",
    "      dic[col[3]] = \"\"\n",
    "    try:\n",
    "      dic[col[4]] = animeEndDate(path)\n",
    "    except Exception:\n",
    "      dic[col[4]] = \"\"\n",
    "    dic[col[5]]= animeNumMembers(path)\n",
    "    dic[col[6]]= animeScore(path)\n",
    "    dic[col[7]]= animeUsers(path)\n",
    "    dic[col[8]]= animeRank(path)\n",
    "    dic[col[9]]= animePopularity(path)\n",
    "    dic[col[10]]= animeDescription(path)\n",
    "    try:\n",
    "      dic[col[11]]= animeRelated(path)\n",
    "    except Exception:\n",
    "      dic[col[11]] = \"\"\n",
    "    dic[col[12]]= animeCharacter(path)\n",
    "    dic[col[13]]= animeVoices(path)\n",
    "    try:\n",
    "      dic[col[14]]= animeStaff(path)\n",
    "    except Exception:\n",
    "       dic[col[14]] = \"\"\n",
    "    with open('/content/drive/MyDrive/Anime_folderpage'+str(((i-1)//50)+1)+'/anime_'+str(i)+ '.tsv', 'w',encoding=\"utf-8\") as page:\n",
    "      i += 1\n",
    "      for c in col:\n",
    "        if c in dic:\n",
    "           page.write(str(dic[c]) + '\\t')\n",
    "        else:\n",
    "          page.write(' \\t')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81858a-cc76-4bf6-8dab-906b174651d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tsv\n",
    "with open('/content/drive/MyDrive/Anime_folderpage_name'+ '.tsv', 'w',encoding=\"utf-8\") as page:\n",
    "  for c in col:\n",
    "    page.write(c+'\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc2a9f-2944-4d81-bd1d-784ad8c4436e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8fd7a0-5578-4077-9ae2-90249dfed174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.DataFrame(columns = ['animeTitle', 'animeType', 'animeNumEpisode', 'releaseDate', 'endDate', 'animeNumMembers', 'animeScore', \\\n",
    "           'animeUsers', 'animeRank', 'animePopularity', 'animeDescription', 'animeRelated', 'animeCharacters', \\\n",
    "           'animeVoices', 'animeStaff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d494585-9c08-40b3-86d9-e62b9b3b2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19127/19127 [02:58<00:00, 106.95it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"./Final database/anime_\"\n",
    "def fillcsv(m,n):\n",
    "    for elem in tqdm(range(m,n)):\n",
    "        tsv_file = open(path+str(elem)+\".tsv\")\n",
    "        read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        cont = 0\n",
    "        for anime in read_tsv:\n",
    "            if cont == 1:\n",
    "                anime = anime[0:15]\n",
    "                df.loc[elem] = anime\n",
    "            cont +=1\n",
    "fillcsv(1,19128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268c5702-e93d-41f5-bcc1-4f600f84f0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeType</th>\n",
       "      <th>animeNumEpisode</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>animeNumMembers</th>\n",
       "      <th>animeScore</th>\n",
       "      <th>animeUsers</th>\n",
       "      <th>animeRank</th>\n",
       "      <th>animePopularity</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>animeRelated</th>\n",
       "      <th>animeCharacters</th>\n",
       "      <th>animeVoices</th>\n",
       "      <th>animeStaff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-05 00:00:00</td>\n",
       "      <td>2010-07-04 00:00:00</td>\n",
       "      <td>2674644</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1622384</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>['Fullmetal Alchemist', 'Fullmetal Alchemist: ...</td>\n",
       "      <td>['Elric, Edward', 'Elric, Alphonse', 'Mustang,...</td>\n",
       "      <td>['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...</td>\n",
       "      <td>[['Cook Justin', ['Producer']], ['Yonai Norito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gintama°</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>2015-04-08 00:00:00</td>\n",
       "      <td>2016-03-30 00:00:00</td>\n",
       "      <td>483584</td>\n",
       "      <td>9.09</td>\n",
       "      <td>169476</td>\n",
       "      <td>2</td>\n",
       "      <td>337</td>\n",
       "      <td>Gintoki, Shinpachi, and Kagura return as the f...</td>\n",
       "      <td>['Gintama', 'Gintama Movie 2: Kanketsu-hen - Y...</td>\n",
       "      <td>['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...</td>\n",
       "      <td>['Sugita, Tomokazu', 'Kugimiya, Rie', 'Sakaguc...</td>\n",
       "      <td>[['Fujita Youichi', ['Director', 'Storyboard',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>TV</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-04-29 00:00:00</td>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>1594869</td>\n",
       "      <td>9.09</td>\n",
       "      <td>1087519</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>['Shingeki no Kyojin', 'Shingeki no Kyojin Sea...</td>\n",
       "      <td>['Levi', 'Ackerman, Mikasa', 'Yeager, Eren', '...</td>\n",
       "      <td>['Kamiya, Hiroshi', 'Ishikawa, Yui', 'Kaji, Yu...</td>\n",
       "      <td>[['Yabuta Shuuhei', ['Producer']], ['Wada Jouj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-04-06 00:00:00</td>\n",
       "      <td>2011-09-14 00:00:00</td>\n",
       "      <td>2090123</td>\n",
       "      <td>9.09</td>\n",
       "      <td>1109700</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>The self-proclaimed mad scientist Rintarou Oka...</td>\n",
       "      <td>['Steins;Gate', 'ChäoS;HEAd', 'Robotics;Notes'...</td>\n",
       "      <td>['Okabe, Rintarou', 'Makise, Kurisu', 'Shiina,...</td>\n",
       "      <td>['Miyano, Mamoru', 'Imai, Asami', 'Hanazawa, K...</td>\n",
       "      <td>[['Iwasa Gaku', ['Producer']], ['Yasuda Takesh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fruits Basket: The Final</td>\n",
       "      <td>TV</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-04-06 00:00:00</td>\n",
       "      <td>2021-06-29 00:00:00</td>\n",
       "      <td>274818</td>\n",
       "      <td>9.07</td>\n",
       "      <td>113310</td>\n",
       "      <td>5</td>\n",
       "      <td>651</td>\n",
       "      <td>Hundreds of years ago, the Chinese Zodiac spir...</td>\n",
       "      <td>['Fruits Basket', 'Fruits Basket 2nd Season']</td>\n",
       "      <td>['Souma, Kyou', 'Honda, Tooru', 'Souma, Yuki',...</td>\n",
       "      <td>['Uchida, Yuuma', 'Iwami, Manaka', 'Shimazaki,...</td>\n",
       "      <td>[['Ibata Yoshihide', ['Director']], ['Aketagaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19123</th>\n",
       "      <td>Kaihouku: Chikan Harem</td>\n",
       "      <td>OVA</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-03-25 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18234</td>\n",
       "      <td></td>\n",
       "      <td>['Tsuukin Kairaku: Chikan de Go!!']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19124</th>\n",
       "      <td>Konbini Shoujo Z</td>\n",
       "      <td>OVA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>559</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12775</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19125</th>\n",
       "      <td>Korogashi Ryouta</td>\n",
       "      <td>OVA</td>\n",
       "      <td>3</td>\n",
       "      <td>1990-11-21 00:00:00</td>\n",
       "      <td>1991-11-21 00:00:00</td>\n",
       "      <td>310</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14511</td>\n",
       "      <td>Takao Ryota is a pervy but well-meaning biker-...</td>\n",
       "      <td>['Korogashi Ryouta']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['Ochiai Masamune', ['Director']]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19126</th>\n",
       "      <td>Kyonyuu Elf Oyako Saimin</td>\n",
       "      <td>OVA</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-28 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>128</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17357</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>['Agraliel, Ephildis', 'Agraliel, Almia']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['Raika Ken', ['Director']]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19127</th>\n",
       "      <td>Mahou Shoujo Elena DVD-BOX Special</td>\n",
       "      <td>Special</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-11 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>330</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14501</td>\n",
       "      <td>Short special included in the DVD-BOX of Mahou...</td>\n",
       "      <td>['Mahou Shoujo Elena']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19127 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               animeTitle animeType animeNumEpisode  \\\n",
       "1        Fullmetal Alchemist: Brotherhood        TV              64   \n",
       "2                                Gintama°        TV              51   \n",
       "3      Shingeki no Kyojin Season 3 Part 2        TV              10   \n",
       "4                             Steins;Gate        TV              24   \n",
       "5                Fruits Basket: The Final        TV              13   \n",
       "...                                   ...       ...             ...   \n",
       "19123              Kaihouku: Chikan Harem       OVA               1   \n",
       "19124                    Konbini Shoujo Z       OVA                   \n",
       "19125                    Korogashi Ryouta       OVA               3   \n",
       "19126            Kyonyuu Elf Oyako Saimin       OVA               2   \n",
       "19127  Mahou Shoujo Elena DVD-BOX Special   Special               1   \n",
       "\n",
       "               releaseDate              endDate animeNumMembers animeScore  \\\n",
       "1      2009-04-05 00:00:00  2010-07-04 00:00:00         2674644       9.16   \n",
       "2      2015-04-08 00:00:00  2016-03-30 00:00:00          483584       9.09   \n",
       "3      2019-04-29 00:00:00  2019-07-01 00:00:00         1594869       9.09   \n",
       "4      2011-04-06 00:00:00  2011-09-14 00:00:00         2090123       9.09   \n",
       "5      2021-04-06 00:00:00  2021-06-29 00:00:00          274818       9.07   \n",
       "...                    ...                  ...             ...        ...   \n",
       "19123  2007-03-25 00:00:00                                   78              \n",
       "19124                                                       559              \n",
       "19125  1990-11-21 00:00:00  1991-11-21 00:00:00             310              \n",
       "19126  2022-01-28 00:00:00                                  128              \n",
       "19127  2015-12-11 00:00:00                                  330              \n",
       "\n",
       "      animeUsers animeRank animePopularity  \\\n",
       "1        1622384         1               3   \n",
       "2         169476         2             337   \n",
       "3        1087519         3              33   \n",
       "4        1109700         4              11   \n",
       "5         113310         5             651   \n",
       "...          ...       ...             ...   \n",
       "19123                                18234   \n",
       "19124                                12775   \n",
       "19125                                14511   \n",
       "19126                                17357   \n",
       "19127                                14501   \n",
       "\n",
       "                                        animeDescription  \\\n",
       "1      After a horrific alchemy experiment goes wrong...   \n",
       "2      Gintoki, Shinpachi, and Kagura return as the f...   \n",
       "3      Seeking to restore humanity's diminishing hope...   \n",
       "4      The self-proclaimed mad scientist Rintarou Oka...   \n",
       "5      Hundreds of years ago, the Chinese Zodiac spir...   \n",
       "...                                                  ...   \n",
       "19123                                                      \n",
       "19124                                                      \n",
       "19125  Takao Ryota is a pervy but well-meaning biker-...   \n",
       "19126                                                      \n",
       "19127  Short special included in the DVD-BOX of Mahou...   \n",
       "\n",
       "                                            animeRelated  \\\n",
       "1      ['Fullmetal Alchemist', 'Fullmetal Alchemist: ...   \n",
       "2      ['Gintama', 'Gintama Movie 2: Kanketsu-hen - Y...   \n",
       "3      ['Shingeki no Kyojin', 'Shingeki no Kyojin Sea...   \n",
       "4      ['Steins;Gate', 'ChäoS;HEAd', 'Robotics;Notes'...   \n",
       "5          ['Fruits Basket', 'Fruits Basket 2nd Season']   \n",
       "...                                                  ...   \n",
       "19123                ['Tsuukin Kairaku: Chikan de Go!!']   \n",
       "19124                                                      \n",
       "19125                               ['Korogashi Ryouta']   \n",
       "19126                                                      \n",
       "19127                             ['Mahou Shoujo Elena']   \n",
       "\n",
       "                                         animeCharacters  \\\n",
       "1      ['Elric, Edward', 'Elric, Alphonse', 'Mustang,...   \n",
       "2      ['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...   \n",
       "3      ['Levi', 'Ackerman, Mikasa', 'Yeager, Eren', '...   \n",
       "4      ['Okabe, Rintarou', 'Makise, Kurisu', 'Shiina,...   \n",
       "5      ['Souma, Kyou', 'Honda, Tooru', 'Souma, Yuki',...   \n",
       "...                                                  ...   \n",
       "19123                                                 []   \n",
       "19124                                                 []   \n",
       "19125                                                 []   \n",
       "19126          ['Agraliel, Ephildis', 'Agraliel, Almia']   \n",
       "19127                                                 []   \n",
       "\n",
       "                                             animeVoices  \\\n",
       "1      ['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...   \n",
       "2      ['Sugita, Tomokazu', 'Kugimiya, Rie', 'Sakaguc...   \n",
       "3      ['Kamiya, Hiroshi', 'Ishikawa, Yui', 'Kaji, Yu...   \n",
       "4      ['Miyano, Mamoru', 'Imai, Asami', 'Hanazawa, K...   \n",
       "5      ['Uchida, Yuuma', 'Iwami, Manaka', 'Shimazaki,...   \n",
       "...                                                  ...   \n",
       "19123                                                 []   \n",
       "19124                                                 []   \n",
       "19125                                                 []   \n",
       "19126                                                 []   \n",
       "19127                                                 []   \n",
       "\n",
       "                                              animeStaff  \n",
       "1      [['Cook Justin', ['Producer']], ['Yonai Norito...  \n",
       "2      [['Fujita Youichi', ['Director', 'Storyboard',...  \n",
       "3      [['Yabuta Shuuhei', ['Producer']], ['Wada Jouj...  \n",
       "4      [['Iwasa Gaku', ['Producer']], ['Yasuda Takesh...  \n",
       "5      [['Ibata Yoshihide', ['Director']], ['Aketagaw...  \n",
       "...                                                  ...  \n",
       "19123                                                     \n",
       "19124                                                     \n",
       "19125                [['Ochiai Masamune', ['Director']]]  \n",
       "19126                      [['Raika Ken', ['Director']]]  \n",
       "19127                                                     \n",
       "\n",
       "[19127 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c7d90770-d3d2-463d-ad83-11b6926fbde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animeTitle                           Bikkuriman: Moen Zone no Himitsu\n",
       "animeType                                                       Movie\n",
       "animeNumEpisode                                                     1\n",
       "releaseDate                                       1988-07-09 00:00:00\n",
       "endDate                                                              \n",
       "animeNumMembers                                                   263\n",
       "animeScore                                                           \n",
       "animeUsers                                                           \n",
       "animeRank                                                       15009\n",
       "animePopularity                                                 15027\n",
       "animeDescription                                                     \n",
       "animeRelated                                           ['Bikkuriman']\n",
       "animeCharacters                                                    []\n",
       "animeVoices                                                        []\n",
       "animeStaff          [['Aoyama Mitsuru', ['Animation Director']], [...\n",
       "Name: 15009, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[15009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d4f44e23-539b-49ad-9a68-372381a53093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df.to_csv('Animeds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87ecef-17e3-47ae-add5-90a0d61e9488",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe87d64-6a56-4426-bb41-3d1ff98fdb9b",
   "metadata": {},
   "source": [
    "Now, we want to create two different Search Engines that, given as input a query, return the animes that match the query.\n",
    "\n",
    "First, you must pre-process all the information collected for each anime by:\n",
    "\n",
    "+ Removing stopwords\n",
    "+ Removing punctuation\n",
    "+ Stemming\n",
    "+ Anything else you think it's needed\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3297b7-b048-4a97-a6f4-98f861924aa6",
   "metadata": {},
   "source": [
    "- Importing stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b072ec-2bdd-4fd6-965d-3d5a7f62cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Filippo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f228654-7ae9-4cae-9de1-aea547b23868",
   "metadata": {},
   "source": [
    "- removing punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37388baf-0e8a-47e5-bd8a-ea5fa820661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seeking to restore humanitys diminishing hope the Survey Corps embark on a mission to retake Wall Maria where the battle against the merciless Titans takes the stage once againReturning to the tattered Shiganshina District that was once his home Eren Yeager and the Corps find the town oddly unoccupied by Titans Even after the outer gate is plugged they strangely encounter no opposition The mission progresses smoothly until Armin Arlert highly suspicious of the enemys absence discovers distressing signs of a potential scheme against them Shingeki no Kyojin Season 3 Part 2 follows Eren as he vows to take back everything that was once his Alongside him the Survey Corps strive—through countless sacrifices—to carve a path towards victory and uncover the secrets locked away in the Yeager familys basement'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringa = \"Seeking to restore humanity's diminishing hope, the Survey Corps embark on a mission to retake Wall Maria, where the battle against the merciless Titans takes the stage once again.Returning to the tattered Shiganshina District that was once his home, Eren Yeager and the Corps find the town oddly unoccupied by Titans. Even after the outer gate is plugged, they strangely encounter no opposition. The mission progresses smoothly until Armin Arlert, highly suspicious of the enemy's absence, discovers distressing signs of a potential scheme against them. Shingeki no Kyojin Season 3 Part 2 follows Eren as he vows to take back everything that was once his. Alongside him, the Survey Corps strive—through countless sacrifices—to carve a path towards victory and uncover the secrets locked away in the Yeager family's basement\"\n",
    "stringa.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cb66b-0cc8-4a09-9bc8-a0b1b095bac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2.1 Conjunctive query\n",
    "Here we decided to proceed without a vocabulary for the first search engine. Word_index is the inverted index that was asked to create, linking to each word the documents that contain it. However for construction purposes it is a list of lists and later on we will create a function (listoflists) to unpack it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1d2a9db-77c5-4da2-a4b0-75854eb6d6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 19127/19127 [04:53<00:00, 65.28it/s]\n"
     ]
    }
   ],
   "source": [
    "word_index = defaultdict(list)\n",
    "#n will run through the length of the dataframe\n",
    "n = df.shape[0]\n",
    "for i in tqdm(range(0,n)):\n",
    "    #fetching the anime descriptions\n",
    "    desc = str(df.iloc[i]['animeDescription'])\n",
    "    splitted = desc.translate(str.maketrans('', '', string.punctuation)).split(\" \")\n",
    "    #creating the dictionary for the indices\n",
    "    for word in splitted:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords.words('english'):\n",
    "            if word not in word_index:\n",
    "                word_index[word] = [[i]]\n",
    "            else:\n",
    "                if [i] not in word_index[word]:\n",
    "                    word_index[word].append([i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "368dc8cc-bd8d-4564-833e-5ce2c66ddd80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[364], [400], [1468], [1962], [2015], [2294], [4339], [4673], [8969], [9229]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['saiyan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f70907-7d6b-471f-afe2-dd2f82d69c41",
   "metadata": {},
   "source": [
    "Since we had problems with Urls (we captured them but the order of some animes changed later on) we deviced a return url function and a particular display function made of if's and elses to accomodate for this problem, the engine function is overall pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "803daa7a-fa57-4856-8203-be4b71538a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listoflists(list):\n",
    "    flat_list = []\n",
    "    for elem in list:\n",
    "        flat_2 = []\n",
    "        for single in elem:\n",
    "            flat_2.append(single[0])\n",
    "        flat_list.append(flat_2)\n",
    "    return flat_list\n",
    "\n",
    "def ReturnUrl(index):\n",
    "    f = open(\"./urls.txt\", encoding=\"utf8\")\n",
    "    stringa = \"\"\n",
    "    for i, line in enumerate(f):\n",
    "        if i == index:\n",
    "            stringa = line\n",
    "    return stringa\n",
    "\n",
    "def search_engine1(query,dataset):\n",
    "  query = query.split(\" \")\n",
    "  f = len(query)\n",
    "  query_indices = []\n",
    "  for index in query:\n",
    "    query_indices.append(word_index[index])  \n",
    "  query_indices = set.intersection(*map(set,listoflists(query_indices)))\n",
    "  query_index = list(set(query_indices))\n",
    "  return(displayresults(query_index))\n",
    "\n",
    "def displayresults(lista):\n",
    "    disp_res = pd.DataFrame()\n",
    "    disp_res = pd.DataFrame(columns = ['Anime Title','Anime Description','Anime URL'])\n",
    "    res = []\n",
    "    for i in lista:\n",
    "        roba = []\n",
    "        roba.append(df.iloc[i]['animeTitle'])\n",
    "        roba.append(df.iloc[i]['animeDescription'])\n",
    "        if i == 1468:\n",
    "            roba.append(ReturnUrl(i-1))\n",
    "        elif i >372:\n",
    "            roba.append(ReturnUrl(i+1))\n",
    "        else:\n",
    "            roba.append(ReturnUrl(i))\n",
    "        res.append(roba)\n",
    "    index = 0\n",
    "    for elem in res:\n",
    "        disp_res.loc[index] = elem\n",
    "        index += 1\n",
    "    return(display(disp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "accd8da9-9ce5-4877-8ebf-9764f3f7e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your anime features:  saiyan race\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>Anime Description</th>\n",
       "      <th>Anime URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>Five years after winning the World Martial Art...</td>\n",
       "      <td>https://myanimelist.net/anime/813/Dragon_Ball_Z\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Anime Title  \\\n",
       "0                           Dragon Ball Super: Broly   \n",
       "1  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "2                                      Dragon Ball Z   \n",
       "\n",
       "                                   Anime Description  \\\n",
       "0  Forty-one years ago on Planet Vegeta, home of ...   \n",
       "1  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "2  Five years after winning the World Martial Art...   \n",
       "\n",
       "                                           Anime URL  \n",
       "0  https://myanimelist.net/anime/36946/Dragon_Bal...  \n",
       "1  https://myanimelist.net/anime/986/Dragon_Ball_...  \n",
       "2  https://myanimelist.net/anime/813/Dragon_Ball_Z\\n  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = str(input(\"Insert your anime features: \"))\n",
    "search_engine1(query,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744ec0a-d3d7-43ec-93fc-cbf5bbf4c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving word index\n",
    "with open('word_index.pkl', 'wb',) as f:\n",
    "    pickle.dump(file=f,obj = word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01ca85-88ec-4e2f-85c9-babc85152b15",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score\n",
    "\n",
    "Here the vocabulary was created by the vectorizer and the inverted index after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f06944-f2b8-4e9c-9a33-fcb59bfba4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be471fef-28f1-4c2f-8354-094e3a0b3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training it and creating the vocabulary\n",
    "n = df.shape[0]\n",
    "descriptions = [str(df.iloc[index]['animeDescription']) for index in range(n)]\n",
    "tf_idf_scores = vectorizer.fit_transform(iter(descriptions))\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab_2 = {k: v for v, k in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd9c42-cb82-4772-a9f2-2bc9bf06a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the vocabulary\n",
    "with open('vocabulary.pkl','wb') as f:\n",
    "    pickle.dump(file=f,obj = vocab_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29c2a6-7f62-44cf-b386-73a6b03a9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the inverted index for 2.2 using the vocabulary\n",
    "dicto = tf_idf_scores.T.todok()\n",
    "it = dicto.keys()\n",
    "next(iter(it))[0]\n",
    "inverted_index_2 = defaultdict(list)\n",
    "dicto.keys()\n",
    "for tup in tqdm(iter(dicto.keys())):\n",
    "    wrd = tup[0]\n",
    "    if wrd not in inverted_index_2:           \n",
    "        inverted_index_2[wrd] = [(tup[1], dicto[tup])]\n",
    "    else:\n",
    "        inverted_index_2[wrd].append(tuple((tup[1], dicto[tup])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3abb2-1028-4dd2-aeab-a93fc5c63b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the inverted index part 2\n",
    "with open('inverted index 2.pkl', 'wb',) as f:\n",
    "    pickle.dump(file=f,obj = inverted_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4948515-02fb-4eb7-999f-8bd4a987ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(388, 0.09378575745668703),\n",
       " (1373, 0.3424286505006758),\n",
       " (3796, 0.15218341701961385),\n",
       " (3859, 0.29293276550671893),\n",
       " (4013, 0.09096971424220497),\n",
       " (4467, 0.15836088560040337),\n",
       " (5115, 0.23562617888158202),\n",
       " (7388, 0.28559304142938974),\n",
       " (9268, 0.3642537322163859),\n",
       " (10928, 0.0877614230070796),\n",
       " (17963, 0.12473893111406961),\n",
       " (18414, 0.09824630606979153),\n",
       " (18460, 0.1473290026631456)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each word contains the docs which have it and its tf-idf score\n",
    "inverted_index_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b272a-cace-4494-a782-3b4af7ec8834",
   "metadata": {},
   "source": [
    "Down here we created a new class to accomodate for heap structure necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f78dc76-c43f-4e7d-a8cc-f8a860138893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class anime:\n",
    "    def __init__(self, id, name,  cosine):\n",
    "\n",
    "        self.id = id\n",
    "        \n",
    "        self.name = name\n",
    "\n",
    "        self.cosine = cosine\n",
    "\n",
    "    def __int__(self):        \n",
    "\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fdd2828-7e5a-4f75-89aa-7dd19a2e5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we had to modify displayresults to accomodate for the cosine similarity needed\n",
    "def displayresults2(lista):\n",
    "    disp_res = pd.DataFrame()\n",
    "    disp_res = pd.DataFrame(columns = ['Anime Title','Anime Description','Anime URL','Cosine similarity'])\n",
    "    res = []\n",
    "    for an in lista:\n",
    "        roba = []\n",
    "        roba.append(df.iloc[an.name]['animeTitle'])\n",
    "        roba.append(df.iloc[an.name]['animeDescription'])\n",
    "        if an.name == 1468:\n",
    "            roba.append(ReturnUrl(an.name-1))\n",
    "        elif an.name >372:\n",
    "            roba.append(ReturnUrl(an.name+1))\n",
    "        else:\n",
    "            roba.append(ReturnUrl(an.name))\n",
    "        roba.append(an.cosine)\n",
    "        res.append(roba)\n",
    "    index = 0\n",
    "    for elem in res:\n",
    "        disp_res.loc[index] = elem\n",
    "        index += 1\n",
    "    return(display(disp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3b45dee-2290-4d9f-aa0e-ca251edda73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_engine2(dataset,topk):\n",
    "    query = str(input(\"Search these words: \") or 'saiyan race male')\n",
    "    query = [query]\n",
    "    \n",
    "    # we used a new vectorizer on the query but with the same vocabulary\n",
    "    tf_vect = TfidfVectorizer(stop_words='english',vocabulary=vocab_2) \n",
    "    tf_idf_query = tf_vect.fit_transform(query)\n",
    "    tf_idf_query = tf_idf_query.todok()\n",
    "    tf_idf_query = list(tf_idf_query.values())\n",
    "    \n",
    "    # after having the vector of tf-idf values for the query we create the one for the documents\n",
    "    query = query[0].split(\" \")\n",
    "    docs_to_check = {}\n",
    "    wrd_count = 0\n",
    "    for word in set(query):\n",
    "        # get index\n",
    "        id_w = vocab_2[word]\n",
    "        # get documents\n",
    "        for elem in inverted_index_2[id_w]:\n",
    "            # add to dictionary and set an empty vector to contain tf-idf values\n",
    "            if elem[0] not in docs_to_check:\n",
    "                docs_to_check[elem[0]] = np.zeros(len(set(query)))\n",
    "            # fill the vector whenever you encounter a word that fits, else leave zero\n",
    "            docs_to_check[elem[0]][wrd_count] = elem[1]\n",
    "        wrd_count+=1\n",
    "    \n",
    "    # calculate cosine similarities\n",
    "    result = [] \n",
    "    count=0\n",
    "    for doc, vector in docs_to_check.items():      \n",
    "        doc_sim = 1 - scipy.spatial.distance.cosine(tf_idf_query,vector)\n",
    "        info = anime(id=count,name=doc, cosine=doc_sim)\n",
    "        # append anime class values to result\n",
    "        result.append(info)\n",
    "        docs_to_check[doc] = doc_sim\n",
    "        count+=1\n",
    "    \n",
    "    # function to sort heap\n",
    "    def sortkey(anime):\n",
    "        return anime.cosine\n",
    "    \n",
    "    highest_cosine = heapq.nlargest(topk, result, key = sortkey)\n",
    "    \n",
    "    \n",
    "    return(displayresults2(highest_cosine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a618ce9-40ee-4a9a-9c68-b5d989f9fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Search these words:  principle banning human transmutation boys attempted bring recently deceased mother\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>Anime Description</th>\n",
       "      <th>Anime URL</th>\n",
       "      <th>Cosine similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>https://myanimelist.net/anime/5114/Fullmetal_A...</td>\n",
       "      <td>0.958120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shigatsu wa Kimi no Uso</td>\n",
       "      <td>Music accompanies the path of the human metron...</td>\n",
       "      <td>https://myanimelist.net/anime/23273/Shigatsu_w...</td>\n",
       "      <td>0.546310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Choujin Densetsu Urotsukidouji: Mirai-hen</td>\n",
       "      <td>Twenty-five years ago, the world was annihilat...</td>\n",
       "      <td>https://myanimelist.net/anime/34758/Momoiro_Bo...</td>\n",
       "      <td>0.546310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detective Conan Movie 06: The Phantom of Baker...</td>\n",
       "      <td>Noah's Ark—the latest in VR technology and a m...</td>\n",
       "      <td>https://myanimelist.net/anime/1365/Detective_C...</td>\n",
       "      <td>0.545303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Anime Title  \\\n",
       "0                   Fullmetal Alchemist: Brotherhood   \n",
       "1                            Shigatsu wa Kimi no Uso   \n",
       "2          Choujin Densetsu Urotsukidouji: Mirai-hen   \n",
       "3  Detective Conan Movie 06: The Phantom of Baker...   \n",
       "\n",
       "                                   Anime Description  \\\n",
       "0  After a horrific alchemy experiment goes wrong...   \n",
       "1  Music accompanies the path of the human metron...   \n",
       "2  Twenty-five years ago, the world was annihilat...   \n",
       "3  Noah's Ark—the latest in VR technology and a m...   \n",
       "\n",
       "                                           Anime URL  Cosine similarity  \n",
       "0  https://myanimelist.net/anime/5114/Fullmetal_A...           0.958120  \n",
       "1  https://myanimelist.net/anime/23273/Shigatsu_w...           0.546310  \n",
       "2  https://myanimelist.net/anime/34758/Momoiro_Bo...           0.546310  \n",
       "3  https://myanimelist.net/anime/1365/Detective_C...           0.545303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_engine2(df,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc7ec3-b0b4-417a-948d-283d4efbd339",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Define a new score\n",
    "Given that all functions were created before in part 3 we worked with stuff especially from part 2.1\n",
    "We decided not to use heap structure but move another way, we let the user choose more information over a simple query (anime type and a minimum score) and store using vectors which anime had more features which met the queries. We still put the priority over the textual query, using only animes which met the query requirement but scoring them according to the jaccard similarity using one/zero vectors to express if the queries were met. Basically dividing the results in classes where they met from 3 to 1 requirements. Lastly esults within the same class were displayed according to animeRanking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23fda9d5-e169-4550-9457-04dd5cea41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_engine3(dataset,topk):\n",
    "    # inputs\n",
    "    query = str(input(\"Search these words: \"))\n",
    "    type_ = str(input('Movie, Music, ONA, OVA, Special, TV or nan '))\n",
    "    if type_ not in ['Movie', 'Music', 'ONA', 'OVA', 'Special', 'TV', 'nan','']:\n",
    "        raise ValueError('Choose between the suggested types')\n",
    "    try:\n",
    "        score = float(input(\"Minimum score between 1 and 10 \") or 0)\n",
    "    except ValueError:\n",
    "        raise ValueError('Please input a number')\n",
    "    query = query.split(\" \")\n",
    "\n",
    "    # getting indices \n",
    "    query_indices = []\n",
    "    for index in query:\n",
    "        query_indices.append(word_index[index])  \n",
    "    query_indices = set.intersection(*map(set,listoflists(query_indices)))\n",
    "    \n",
    "    if type_ != '':\n",
    "        type_indices = set(dataset.index[dataset.animeType == type_])\n",
    "    score_indices = set(dataset.index[dataset.animeScore >= score])\n",
    "    \n",
    "    # using Jaccard similarity to get best results \n",
    "    output_indices = {}\n",
    "    for index in tqdm(query_indices):\n",
    "        vect = [0,0,0]\n",
    "        if index in query_indices:\n",
    "            vect[0] = 1\n",
    "        if index in type_indices:\n",
    "            vect[1] = 1\n",
    "        if index in score_indices:\n",
    "            vect[2] = 1\n",
    "        js = round(jaccard_score(y_true=[1,1,1],y_pred=vect),2)\n",
    "        if js in output_indices:\n",
    "            output_indices[js].append(index)\n",
    "        else:\n",
    "            output_indices[js] = [index]\n",
    "    output_indices = collections.OrderedDict(sorted(output_indices.items(),reverse=True))\n",
    "    res=[]\n",
    "    # output only top k results not using heap\n",
    "    for listy in output_indices.values():\n",
    "        for el in listy:\n",
    "            res.append(el)\n",
    "            if len(res) == topk:\n",
    "                break\n",
    "        if len(res) == topk:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return(displayresults(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79e6a571-351f-420c-a76f-be0010818421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Search these words:  saiyan\n",
      "Movie, Music, ONA, OVA, Special, TV or nan  TV\n",
      "Minimum score between 1 and 10  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1111.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>Anime Description</th>\n",
       "      <th>Anime URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dragon Ball Super</td>\n",
       "      <td>Seven years after the events of Dragon Ball Z,...</td>\n",
       "      <td>https://myanimelist.net/anime/25183/Gangsta\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>Five years after winning the World Martial Art...</td>\n",
       "      <td>https://myanimelist.net/anime/813/Dragon_Ball_Z\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dragon Ball Z Movie 10: Kiken na Futari! Super...</td>\n",
       "      <td>After his loss to Goku, Broly crash lands and ...</td>\n",
       "      <td>https://myanimelist.net/anime/11809/gdgd_Fairi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dragon Ball Z: The Real 4-D at Super Tenkaichi...</td>\n",
       "      <td>Dragon Ball Z: The Real 4-D at Super Tenkaichi...</td>\n",
       "      <td>https://myanimelist.net/anime/30278/Ghost_Mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dragon Ball Z Movie 11: Super Senshi Gekiha!! ...</td>\n",
       "      <td>Jaga Bada, Mr. Satan's old sparring partner, h...</td>\n",
       "      <td>https://myanimelist.net/anime/9172/Kaitei_Sanm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dragon Ball: Ossu! Kaettekita Son Gokuu to Nak...</td>\n",
       "      <td>Based on an original concept by the original a...</td>\n",
       "      <td>https://myanimelist.net/anime/12225/Galaxy_Ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dragon Ball Z Movie 08: Moetsukiro!! Nessen, R...</td>\n",
       "      <td>As Goku investigates the destruction of the So...</td>\n",
       "      <td>https://myanimelist.net/anime/5684/Fresh_Precu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dragon Ball Z Movie 14: Kami to Kami</td>\n",
       "      <td>Following the defeat of a great adversary, Gok...</td>\n",
       "      <td>https://myanimelist.net/anime/36824/Huyao_Xiao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Anime Title  \\\n",
       "0                                  Dragon Ball Super   \n",
       "1                                      Dragon Ball Z   \n",
       "2  Dragon Ball Z Movie 10: Kiken na Futari! Super...   \n",
       "3  Dragon Ball Z: The Real 4-D at Super Tenkaichi...   \n",
       "4  Dragon Ball Z Movie 11: Super Senshi Gekiha!! ...   \n",
       "5                           Dragon Ball Super: Broly   \n",
       "6  Dragon Ball: Ossu! Kaettekita Son Gokuu to Nak...   \n",
       "7  Dragon Ball Z Movie 08: Moetsukiro!! Nessen, R...   \n",
       "8  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "9               Dragon Ball Z Movie 14: Kami to Kami   \n",
       "\n",
       "                                   Anime Description  \\\n",
       "0  Seven years after the events of Dragon Ball Z,...   \n",
       "1  Five years after winning the World Martial Art...   \n",
       "2  After his loss to Goku, Broly crash lands and ...   \n",
       "3  Dragon Ball Z: The Real 4-D at Super Tenkaichi...   \n",
       "4  Jaga Bada, Mr. Satan's old sparring partner, h...   \n",
       "5  Forty-one years ago on Planet Vegeta, home of ...   \n",
       "6  Based on an original concept by the original a...   \n",
       "7  As Goku investigates the destruction of the So...   \n",
       "8  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "9  Following the defeat of a great adversary, Gok...   \n",
       "\n",
       "                                           Anime URL  \n",
       "0      https://myanimelist.net/anime/25183/Gangsta\\n  \n",
       "1  https://myanimelist.net/anime/813/Dragon_Ball_Z\\n  \n",
       "2  https://myanimelist.net/anime/11809/gdgd_Fairi...  \n",
       "3  https://myanimelist.net/anime/30278/Ghost_Mess...  \n",
       "4  https://myanimelist.net/anime/9172/Kaitei_Sanm...  \n",
       "5  https://myanimelist.net/anime/36946/Dragon_Bal...  \n",
       "6  https://myanimelist.net/anime/12225/Galaxy_Ang...  \n",
       "7  https://myanimelist.net/anime/5684/Fresh_Precu...  \n",
       "8  https://myanimelist.net/anime/986/Dragon_Ball_...  \n",
       "9  https://myanimelist.net/anime/36824/Huyao_Xiao...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_engine3(dataset=df,k = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Laboratorio",
   "language": "python",
   "name": "laboratorio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
